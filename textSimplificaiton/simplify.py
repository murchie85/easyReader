import nltk

# Sample text to be tokenized
text = "This is a sample text string that will be tokenized into words."

# Tokenize the text into words
tokens = nltk.word_tokenize(text)

# Print the resulting list of words
print(tokens)
